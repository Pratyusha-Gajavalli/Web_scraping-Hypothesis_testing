{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d527f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the libraries required\n",
    "import requests\n",
    "import random\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import bs4 as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c4d6a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-ad3547467437>:13: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('chromedriver.exe', options = chrome_options)\n"
     ]
    }
   ],
   "source": [
    "#setting up webdriver\n",
    "from selenium import webdriver\n",
    "path=\"chromedriver.exe\"\n",
    "import time\n",
    "import random\n",
    "import bs4 as bs\n",
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "chrome_options = Options()\n",
    "#chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe', options = chrome_options)\n",
    "\n",
    "time.sleep(3)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b36bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping product details of women-jumpsuites\n",
    "urls=['https://www2.hm.com/en_us/women/products/jumpsuits-rompers.html?sort=stock&image-size=small&image=model&offset=0&page-size=1000']\n",
    "product_links=[]\n",
    "for url in urls:\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(url)\n",
    "    #time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')    \n",
    "    tablef=soup.find_all('h3',class_=\"item-heading\")\n",
    "    for product in tablef:\n",
    "        product_links.append(\"https://www2.hm.com\"+product.a['href'])\n",
    "rows=[]\n",
    "for prod in product_links:\n",
    "    values=[]\n",
    "    values.append(prod)\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(prod)\n",
    "    time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        x=soup.find('dd')\n",
    "        text=x.text\n",
    "        if 'model' in text:\n",
    "            values.append(\"yes\")\n",
    "        else:\n",
    "            if len(soup.find_all('figure',class_=\"pdp-secondary-image pdp-image\"))>=2:\n",
    "                values.append(\"yes\")\n",
    "            else:\n",
    "                values.append(\"no\")\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        r=soup.find('span',class_=\"reviews-number\")\n",
    "        values.append(r.text[9:-1])\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        stars=soup.find_all('span',class_=\"star\")\n",
    "        star_values=[]\n",
    "        for s in range(5):\n",
    "            att=stars[s].attrs\n",
    "            star_values.append(list(att.values())[0])\n",
    "        star_values2=[b for a in star_values for b in a] \n",
    "        if 'full' in star_values2:\n",
    "            ind=star_values2.index('full')\n",
    "            rating=ind\n",
    "        elif 'half' in star_values2:\n",
    "            ind=star_values2.index('half')\n",
    "            rating=ind-0.5\n",
    "        else:\n",
    "            rating=0\n",
    "        values.append(rating)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        desc=soup.find('p',class_=\"pdp-description-text\")\n",
    "        values.append(desc.text)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    rows.append(values)\n",
    "    \n",
    "women_jumpsuites = pd.DataFrame(rows, columns =['product', 'model_present', 'no_of_reviews', 'avg_rating', 'description'])\n",
    "women_jumpsuites.to_csv('women_jumpsuites.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43751630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping product details of women-shirts\n",
    "urls=['https://www2.hm.com/en_us/women/products/shirts-blouses.html?sort=stock&image-size=small&image=model&offset=0&page-size=1000']\n",
    "product_links=[]\n",
    "for url in urls:\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(url)\n",
    "    #time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')    \n",
    "    tablef=soup.find_all('h3',class_=\"item-heading\")\n",
    "    for product in tablef:\n",
    "        product_links.append(\"https://www2.hm.com\"+product.a['href'])\n",
    "rows=[]\n",
    "for prod in product_links:\n",
    "    values=[]\n",
    "    values.append(prod)\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(prod)\n",
    "    time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        x=soup.find('dd')\n",
    "        text=x.text\n",
    "        if 'model' in text:\n",
    "            values.append(\"yes\")\n",
    "        else:\n",
    "            if len(soup.find_all('figure',class_=\"pdp-secondary-image pdp-image\"))>=2:\n",
    "                values.append(\"yes\")\n",
    "            else:\n",
    "                values.append(\"no\")\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        r=soup.find('span',class_=\"reviews-number\")\n",
    "        values.append(r.text[9:-1])\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        stars=soup.find_all('span',class_=\"star\")\n",
    "        star_values=[]\n",
    "        for s in range(5):\n",
    "            att=stars[s].attrs\n",
    "            star_values.append(list(att.values())[0])\n",
    "        star_values2=[b for a in star_values for b in a] \n",
    "        if 'full' in star_values2:\n",
    "            ind=star_values2.index('full')\n",
    "            rating=ind\n",
    "        elif 'half' in star_values2:\n",
    "            ind=star_values2.index('half')\n",
    "            rating=ind-0.5\n",
    "        else:\n",
    "            rating=0\n",
    "        values.append(rating)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        desc=soup.find('p',class_=\"pdp-description-text\")\n",
    "        values.append(desc.text)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    rows.append(values)\n",
    "    \n",
    "women_shirts = pd.DataFrame(rows, columns =['product', 'model_present', 'no_of_reviews', 'avg_rating', 'description'])\n",
    "women_shirts.to_csv('women_shirts.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "86e46902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping product details of women-dresses\n",
    "urls=['https://www2.hm.com/en_us/women/products/dresses.html?sort=stock&image-size=small&image=model&offset=0&page-size=1000']\n",
    "product_links=[]\n",
    "for url in urls:\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(url)\n",
    "    #time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')    \n",
    "    tablef=soup.find_all('h3',class_=\"item-heading\")\n",
    "    for product in tablef:\n",
    "        product_links.append(\"https://www2.hm.com\"+product.a['href'])\n",
    "rows=[]\n",
    "for prod in product_links:\n",
    "    values=[]\n",
    "    values.append(prod)\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(prod)\n",
    "    time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        x=soup.find('dd')\n",
    "        text=x.text\n",
    "        if 'model' in text:\n",
    "            values.append(\"yes\")\n",
    "        else:\n",
    "            if len(soup.find_all('figure',class_=\"pdp-secondary-image pdp-image\"))>=2:\n",
    "                values.append(\"yes\")\n",
    "            else:\n",
    "                values.append(\"no\")\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        r=soup.find('span',class_=\"reviews-number\")\n",
    "        values.append(r.text[9:-1])\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        stars=soup.find_all('span',class_=\"star\")\n",
    "        star_values=[]\n",
    "        for s in range(5):\n",
    "            att=stars[s].attrs\n",
    "            star_values.append(list(att.values())[0])\n",
    "        star_values2=[b for a in star_values for b in a] \n",
    "        if 'full' in star_values2:\n",
    "            ind=star_values2.index('full')\n",
    "            rating=ind\n",
    "        elif 'half' in star_values2:\n",
    "            ind=star_values2.index('half')\n",
    "            rating=ind-0.5\n",
    "        else:\n",
    "            rating=0\n",
    "        values.append(rating)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        desc=soup.find('p',class_=\"pdp-description-text\")\n",
    "        values.append(desc.text)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    rows.append(values)\n",
    "    \n",
    "women_dresses = pd.DataFrame(rows, columns =['product', 'model_present', 'no_of_reviews', 'avg_rating', 'description'])\n",
    "women_dresses.to_csv('women_dresses.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9f1a41f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-126-f88b98ff2175>:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(path)\n"
     ]
    }
   ],
   "source": [
    "#Scraping product details of women-tops\n",
    "urls=['https://www2.hm.com/en_us/women/products/tops.html?sort=stock&image-size=small&image=model&offset=0&page-size=1000']\n",
    "product_links=[]\n",
    "for url in urls:\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(url)\n",
    "    #time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')    \n",
    "    tablef=soup.find_all('h3',class_=\"item-heading\")\n",
    "    for product in tablef:\n",
    "        product_links.append(\"https://www2.hm.com\"+product.a['href'])\n",
    "rows=[]\n",
    "for prod in product_links:\n",
    "    values=[]\n",
    "    values.append(prod)\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(prod)\n",
    "    time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        x=soup.find('dd')\n",
    "        text=x.text\n",
    "        if 'model' in text:\n",
    "            values.append(\"yes\")\n",
    "        else:\n",
    "            if len(soup.find_all('figure',class_=\"pdp-secondary-image pdp-image\"))>=2:\n",
    "                values.append(\"yes\")\n",
    "            else:\n",
    "                values.append(\"no\")\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        r=soup.find('span',class_=\"reviews-number\")\n",
    "        values.append(r.text[9:-1])\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        stars=soup.find_all('span',class_=\"star\")\n",
    "        star_values=[]\n",
    "        for s in range(5):\n",
    "            att=stars[s].attrs\n",
    "            star_values.append(list(att.values())[0])\n",
    "        star_values2=[b for a in star_values for b in a] \n",
    "        if 'full' in star_values2:\n",
    "            ind=star_values2.index('full')\n",
    "            rating=ind\n",
    "        elif 'half' in star_values2:\n",
    "            ind=star_values2.index('half')\n",
    "            rating=ind-0.5\n",
    "        else:\n",
    "            rating=0\n",
    "        values.append(rating)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        desc=soup.find('p',class_=\"pdp-description-text\")\n",
    "        values.append(desc.text)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    rows.append(values)\n",
    "    \n",
    "women_tops = pd.DataFrame(rows, columns =['product', 'model_present', 'no_of_reviews', 'avg_rating', 'description'])\n",
    "women_tops.to_csv('women_tops.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ad73b67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-127-ac6f803d40d7>:6: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(path)\n"
     ]
    }
   ],
   "source": [
    "#Scraping product details of women-jeans\n",
    "urls=['https://www2.hm.com/en_us/women/products/jeans.html?sort=stock&image-size=small&image=model&offset=0&page-size=1000']\n",
    "product_links=[]\n",
    "for url in urls:\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(url)\n",
    "    #time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')    \n",
    "    tablef=soup.find_all('h3',class_=\"item-heading\")\n",
    "    for product in tablef:\n",
    "        product_links.append(\"https://www2.hm.com\"+product.a['href'])\n",
    "rows=[]\n",
    "for prod in product_links:\n",
    "    values=[]\n",
    "    values.append(prod)\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(prod)\n",
    "    time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        x=soup.find('dd')\n",
    "        text=x.text\n",
    "        if 'model' in text:\n",
    "            values.append(\"yes\")\n",
    "        else:\n",
    "            if len(soup.find_all('figure',class_=\"pdp-secondary-image pdp-image\"))>=2:\n",
    "                values.append(\"yes\")\n",
    "            else:\n",
    "                values.append(\"no\")\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        r=soup.find('span',class_=\"reviews-number\")\n",
    "        values.append(r.text[9:-1])\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        stars=soup.find_all('span',class_=\"star\")\n",
    "        star_values=[]\n",
    "        for s in range(5):\n",
    "            att=stars[s].attrs\n",
    "            star_values.append(list(att.values())[0])\n",
    "        star_values2=[b for a in star_values for b in a] \n",
    "        if 'full' in star_values2:\n",
    "            ind=star_values2.index('full')\n",
    "            rating=ind\n",
    "        elif 'half' in star_values2:\n",
    "            ind=star_values2.index('half')\n",
    "            rating=ind-0.5\n",
    "        else:\n",
    "            rating=0\n",
    "        values.append(rating)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        desc=soup.find('p',class_=\"pdp-description-text\")\n",
    "        values.append(desc.text)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    rows.append(values)\n",
    "    \n",
    "women_jeans = pd.DataFrame(rows, columns =['product', 'model_present', 'no_of_reviews', 'avg_rating', 'description'])\n",
    "women_jeans.to_csv('women_jeans.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c302c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping product details of women-shorts\n",
    "urls=['https://www2.hm.com/en_us/women/products/shorts.html?sort=stock&image-size=small&image=model&offset=0&page-size=1000']\n",
    "product_links=[]\n",
    "for url in urls:\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(url)\n",
    "    #time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')    \n",
    "    tablef=soup.find_all('h3',class_=\"item-heading\")\n",
    "    for product in tablef:\n",
    "        product_links.append(\"https://www2.hm.com\"+product.a['href'])\n",
    "rows=[]\n",
    "for prod in product_links:\n",
    "    values=[]\n",
    "    values.append(prod)\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(prod)\n",
    "    time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        x=soup.find('dd')\n",
    "        text=x.text\n",
    "        if 'model' in text:\n",
    "            values.append(\"yes\")\n",
    "        else:\n",
    "            if len(soup.find_all('figure',class_=\"pdp-secondary-image pdp-image\"))>=2:\n",
    "                values.append(\"yes\")\n",
    "            else:\n",
    "                values.append(\"no\")\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        r=soup.find('span',class_=\"reviews-number\")\n",
    "        values.append(r.text[9:-1])\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        stars=soup.find_all('span',class_=\"star\")\n",
    "        star_values=[]\n",
    "        for s in range(5):\n",
    "            att=stars[s].attrs\n",
    "            star_values.append(list(att.values())[0])\n",
    "        star_values2=[b for a in star_values for b in a] \n",
    "        if 'full' in star_values2:\n",
    "            ind=star_values2.index('full')\n",
    "            rating=ind\n",
    "        elif 'half' in star_values2:\n",
    "            ind=star_values2.index('half')\n",
    "            rating=ind-0.5\n",
    "        else:\n",
    "            rating=0\n",
    "        values.append(rating)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        desc=soup.find('p',class_=\"pdp-description-text\")\n",
    "        values.append(desc.text)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    rows.append(values)\n",
    "    \n",
    "women_jeans = pd.DataFrame(rows, columns =['product', 'model_present', 'no_of_reviews', 'avg_rating', 'description'])\n",
    "women_jeans.to_csv('women_jeans.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4c20f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping product details of women-sweaters\n",
    "urls=['https://www2.hm.com/en_us/divided/products/hoodies-sweatshirts.html?sort=stock&image-size=small&image=model&offset=0&page-size=1000']\n",
    "product_links=[]\n",
    "for url in urls:\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(url)\n",
    "    #time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')    \n",
    "    tablef=soup.find_all('h3',class_=\"item-heading\")\n",
    "    for product in tablef:\n",
    "        product_links.append(\"https://www2.hm.com\"+product.a['href'])\n",
    "rows=[]\n",
    "for prod in product_links:\n",
    "    values=[]\n",
    "    values.append(prod)\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(prod)\n",
    "    time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        x=soup.find('dd')\n",
    "        text=x.text\n",
    "        if 'model' in text:\n",
    "            values.append(\"yes\")\n",
    "        else:\n",
    "            if len(soup.find_all('figure',class_=\"pdp-secondary-image pdp-image\"))>=2:\n",
    "                values.append(\"yes\")\n",
    "            else:\n",
    "                values.append(\"no\")\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        r=soup.find('span',class_=\"reviews-number\")\n",
    "        values.append(r.text[9:-1])\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        stars=soup.find_all('span',class_=\"star\")\n",
    "        star_values=[]\n",
    "        for s in range(5):\n",
    "            att=stars[s].attrs\n",
    "            star_values.append(list(att.values())[0])\n",
    "        star_values2=[b for a in star_values for b in a] \n",
    "        if 'full' in star_values2:\n",
    "            ind=star_values2.index('full')\n",
    "            rating=ind\n",
    "        elif 'half' in star_values2:\n",
    "            ind=star_values2.index('half')\n",
    "            rating=ind-0.5\n",
    "        else:\n",
    "            rating=0\n",
    "        values.append(rating)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        desc=soup.find('p',class_=\"pdp-description-text\")\n",
    "        values.append(desc.text)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    rows.append(values)\n",
    "    \n",
    "women_sweaters = pd.DataFrame(rows, columns =['product', 'model_present', 'no_of_reviews', 'avg_rating', 'description'])\n",
    "women_sweaters.to_csv('women_sweaters.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b10f6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping product details of women-shoes\n",
    "urls=['https://www2.hm.com/en_us/women/products/shoes.html?sort=stock&image-size=small&image=model&offset=0&page-size=1000']\n",
    "product_links=[]\n",
    "for url in urls:\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(url)\n",
    "    #time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')    \n",
    "    tablef=soup.find_all('h3',class_=\"item-heading\")\n",
    "    for product in tablef:\n",
    "        product_links.append(\"https://www2.hm.com\"+product.a['href'])\n",
    "rows=[]\n",
    "for prod in product_links:\n",
    "    values=[]\n",
    "    values.append(prod)\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(prod)\n",
    "    time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        x=soup.find('dd')\n",
    "        text=x.text\n",
    "        if 'model' in text:\n",
    "            values.append(\"yes\")\n",
    "        else:\n",
    "            if len(soup.find_all('figure',class_=\"pdp-secondary-image pdp-image\"))>=2:\n",
    "                values.append(\"yes\")\n",
    "            else:\n",
    "                values.append(\"no\")\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        r=soup.find('span',class_=\"reviews-number\")\n",
    "        values.append(r.text[9:-1])\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        stars=soup.find_all('span',class_=\"star\")\n",
    "        star_values=[]\n",
    "        for s in range(5):\n",
    "            att=stars[s].attrs\n",
    "            star_values.append(list(att.values())[0])\n",
    "        star_values2=[b for a in star_values for b in a] \n",
    "        if 'full' in star_values2:\n",
    "            ind=star_values2.index('full')\n",
    "            rating=ind\n",
    "        elif 'half' in star_values2:\n",
    "            ind=star_values2.index('half')\n",
    "            rating=ind-0.5\n",
    "        else:\n",
    "            rating=0\n",
    "        values.append(rating)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        desc=soup.find('p',class_=\"pdp-description-text\")\n",
    "        values.append(desc.text)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    rows.append(values)\n",
    "    \n",
    "women_shoes = pd.DataFrame(rows, columns =['product', 'model_present', 'no_of_reviews', 'avg_rating', 'description'])\n",
    "women_shoes.to_csv('women_shoes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f0478dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-131-f88b98ff2175>:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(path)\n"
     ]
    }
   ],
   "source": [
    "#Scraping product details of women-basics\n",
    "urls=['https://www2.hm.com/en_us/women/products/basics.html?sort=stock&image-size=small&image=model&offset=0&page-size=1000']\n",
    "product_links=[]\n",
    "for url in urls:\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(url)\n",
    "    #time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')    \n",
    "    tablef=soup.find_all('h3',class_=\"item-heading\")\n",
    "    for product in tablef:\n",
    "        product_links.append(\"https://www2.hm.com\"+product.a['href'])\n",
    "rows=[]\n",
    "for prod in product_links:\n",
    "    values=[]\n",
    "    values.append(prod)\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(prod)\n",
    "    time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        x=soup.find('dd')\n",
    "        text=x.text\n",
    "        if 'model' in text:\n",
    "            values.append(\"yes\")\n",
    "        else:\n",
    "            if len(soup.find_all('figure',class_=\"pdp-secondary-image pdp-image\"))>=2:\n",
    "                values.append(\"yes\")\n",
    "            else:\n",
    "                values.append(\"no\")\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        r=soup.find('span',class_=\"reviews-number\")\n",
    "        values.append(r.text[9:-1])\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        stars=soup.find_all('span',class_=\"star\")\n",
    "        star_values=[]\n",
    "        for s in range(5):\n",
    "            att=stars[s].attrs\n",
    "            star_values.append(list(att.values())[0])\n",
    "        star_values2=[b for a in star_values for b in a] \n",
    "        if 'full' in star_values2:\n",
    "            ind=star_values2.index('full')\n",
    "            rating=ind\n",
    "        elif 'half' in star_values2:\n",
    "            ind=star_values2.index('half')\n",
    "            rating=ind-0.5\n",
    "        else:\n",
    "            rating=0\n",
    "        values.append(rating)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        desc=soup.find('p',class_=\"pdp-description-text\")\n",
    "        values.append(desc.text)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    rows.append(values)\n",
    "    \n",
    "women_basics = pd.DataFrame(rows, columns =['product', 'model_present', 'no_of_reviews', 'avg_rating', 'description'])\n",
    "women_basics.to_csv('women_basics.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fae15f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-132-ac6f803d40d7>:6: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(path)\n"
     ]
    }
   ],
   "source": [
    "#Scraping product details of women-tights\n",
    "urls=['https://www2.hm.com/en_us/women/products/socks-tights.html?sort=stock&image-size=small&image=stillLife&offset=0&page-size=1000']\n",
    "product_links=[]\n",
    "for url in urls:\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(url)\n",
    "    #time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')    \n",
    "    tablef=soup.find_all('h3',class_=\"item-heading\")\n",
    "    for product in tablef:\n",
    "        product_links.append(\"https://www2.hm.com\"+product.a['href'])\n",
    "rows=[]\n",
    "for prod in product_links:\n",
    "    values=[]\n",
    "    values.append(prod)\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(prod)\n",
    "    time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        x=soup.find('dd')\n",
    "        text=x.text\n",
    "        if 'model' in text:\n",
    "            values.append(\"yes\")\n",
    "        else:\n",
    "            if len(soup.find_all('figure',class_=\"pdp-secondary-image pdp-image\"))>=2:\n",
    "                values.append(\"yes\")\n",
    "            else:\n",
    "                values.append(\"no\")\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        r=soup.find('span',class_=\"reviews-number\")\n",
    "        values.append(r.text[9:-1])\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        stars=soup.find_all('span',class_=\"star\")\n",
    "        star_values=[]\n",
    "        for s in range(5):\n",
    "            att=stars[s].attrs\n",
    "            star_values.append(list(att.values())[0])\n",
    "        star_values2=[b for a in star_values for b in a] \n",
    "        if 'full' in star_values2:\n",
    "            ind=star_values2.index('full')\n",
    "            rating=ind\n",
    "        elif 'half' in star_values2:\n",
    "            ind=star_values2.index('half')\n",
    "            rating=ind-0.5\n",
    "        else:\n",
    "            rating=0\n",
    "        values.append(rating)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        desc=soup.find('p',class_=\"pdp-description-text\")\n",
    "        values.append(desc.text)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    rows.append(values)\n",
    "    \n",
    "women_tights = pd.DataFrame(rows, columns =['product', 'model_present', 'no_of_reviews', 'avg_rating', 'description'])\n",
    "women_tights.to_csv('women_tights.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a14d5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping product details of women-activewear\n",
    "urls=['https://www2.hm.com/en_us/women/products/workout-clothes.html?sort=stock&image-size=small&image=model&offset=0&page-size=1000']\n",
    "product_links=[]\n",
    "for url in urls:\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(url)\n",
    "    #time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')    \n",
    "    tablef=soup.find_all('h3',class_=\"item-heading\")\n",
    "    for product in tablef:\n",
    "        product_links.append(\"https://www2.hm.com\"+product.a['href'])\n",
    "rows=[]\n",
    "for prod in product_links:\n",
    "    values=[]\n",
    "    values.append(prod)\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(prod)\n",
    "    time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        x=soup.find('dd')\n",
    "        text=x.text\n",
    "        if 'model' in text:\n",
    "            values.append(\"yes\")\n",
    "        else:\n",
    "            if len(soup.find_all('figure',class_=\"pdp-secondary-image pdp-image\"))>=2:\n",
    "                values.append(\"yes\")\n",
    "            else:\n",
    "                values.append(\"no\")\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        r=soup.find('span',class_=\"reviews-number\")\n",
    "        values.append(r.text[9:-1])\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        stars=soup.find_all('span',class_=\"star\")\n",
    "        star_values=[]\n",
    "        for s in range(5):\n",
    "            att=stars[s].attrs\n",
    "            star_values.append(list(att.values())[0])\n",
    "        star_values2=[b for a in star_values for b in a] \n",
    "        if 'full' in star_values2:\n",
    "            ind=star_values2.index('full')\n",
    "            rating=ind\n",
    "        elif 'half' in star_values2:\n",
    "            ind=star_values2.index('half')\n",
    "            rating=ind-0.5\n",
    "        else:\n",
    "            rating=0\n",
    "        values.append(rating)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        desc=soup.find('p',class_=\"pdp-description-text\")\n",
    "        values.append(desc.text)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    rows.append(values)\n",
    "    \n",
    "women_activewear = pd.DataFrame(rows, columns =['product', 'model_present', 'no_of_reviews', 'avg_rating', 'description'])\n",
    "women_activewear.to_csv('women_activewear.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63aaaa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-e73d562dd82d>:4: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(path)\n",
      "<ipython-input-12-e73d562dd82d>:20: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(path)\n"
     ]
    }
   ],
   "source": [
    "#Scraping product details of women-skirts\n",
    "urls=['https://www2.hm.com/en_us/women/products/skirts.html?sort=stock&image-size=small&image=model&offset=0&page-size=1000']\n",
    "product_links=[]\n",
    "for url in urls:\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(url)\n",
    "    #time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')    \n",
    "    tablef=soup.find_all('h3',class_=\"item-heading\")\n",
    "    for product in tablef:\n",
    "        product_links.append(\"https://www2.hm.com\"+product.a['href'])\n",
    "rows=[]\n",
    "for prod in product_links:\n",
    "    values=[]\n",
    "    values.append(prod)\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(prod)\n",
    "    time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        x=soup.find('dd')\n",
    "        text=x.text\n",
    "        if 'model' in text:\n",
    "            values.append(\"yes\")\n",
    "        else:\n",
    "            if len(soup.find_all('figure',class_=\"pdp-secondary-image pdp-image\"))>=2:\n",
    "                values.append(\"yes\")\n",
    "            else:\n",
    "                values.append(\"no\")\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        r=soup.find('span',class_=\"reviews-number\")\n",
    "        values.append(r.text[9:-1])\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        stars=soup.find_all('span',class_=\"star\")\n",
    "        star_values=[]\n",
    "        for s in range(5):\n",
    "            att=stars[s].attrs\n",
    "            star_values.append(list(att.values())[0])\n",
    "        star_values2=[b for a in star_values for b in a] \n",
    "        if 'full' in star_values2:\n",
    "            ind=star_values2.index('full')\n",
    "            rating=ind\n",
    "        elif 'half' in star_values2:\n",
    "            ind=star_values2.index('half')\n",
    "            rating=ind-0.5\n",
    "        else:\n",
    "            rating=0\n",
    "        values.append(rating)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        desc=soup.find('p',class_=\"pdp-description-text\")\n",
    "        values.append(desc.text)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    rows.append(values)\n",
    "    \n",
    "women_skirts = pd.DataFrame(rows, columns =['product', 'model_present', 'no_of_reviews', 'avg_rating', 'description'])\n",
    "women_skirts.to_csv('women_skirts.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c2bf95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping product details of women-blazers\n",
    "urls=['https://www2.hm.com/en_us/women/products/blazers-vests.html?sort=stock&image-size=small&image=model&offset=0&page-size=1000']\n",
    "product_links=[]\n",
    "for url in urls:\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(url)\n",
    "    #time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')    \n",
    "    tablef=soup.find_all('h3',class_=\"item-heading\")\n",
    "    for product in tablef:\n",
    "        product_links.append(\"https://www2.hm.com\"+product.a['href'])\n",
    "rows=[]\n",
    "for prod in product_links:\n",
    "    values=[]\n",
    "    values.append(prod)\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(prod)\n",
    "    time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        x=soup.find('dd')\n",
    "        text=x.text\n",
    "        if 'model' in text:\n",
    "            values.append(\"yes\")\n",
    "        else:\n",
    "            if len(soup.find_all('figure',class_=\"pdp-secondary-image pdp-image\"))>=2:\n",
    "                values.append(\"yes\")\n",
    "            else:\n",
    "                values.append(\"no\")\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        r=soup.find('span',class_=\"reviews-number\")\n",
    "        values.append(r.text[9:-1])\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        stars=soup.find_all('span',class_=\"star\")\n",
    "        star_values=[]\n",
    "        for s in range(5):\n",
    "            att=stars[s].attrs\n",
    "            star_values.append(list(att.values())[0])\n",
    "        star_values2=[b for a in star_values for b in a] \n",
    "        if 'full' in star_values2:\n",
    "            ind=star_values2.index('full')\n",
    "            rating=ind\n",
    "        elif 'half' in star_values2:\n",
    "            ind=star_values2.index('half')\n",
    "            rating=ind-0.5\n",
    "        else:\n",
    "            rating=0\n",
    "        values.append(rating)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        desc=soup.find('p',class_=\"pdp-description-text\")\n",
    "        values.append(desc.text)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    rows.append(values)\n",
    "    \n",
    "women_blazers = pd.DataFrame(rows, columns =['product', 'model_present', 'no_of_reviews', 'avg_rating', 'description'])\n",
    "women_blazers.to_csv('women_blazers.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0492b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping product details of women-jackets\n",
    "urls=['https://www2.hm.com/en_us/women/products/jackets-coats.html?sort=stock&image-size=small&image=model&offset=0&page-size=1000']\n",
    "product_links=[]\n",
    "for url in urls:\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(url)\n",
    "    #time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')    \n",
    "    tablef=soup.find_all('h3',class_=\"item-heading\")\n",
    "    for product in tablef:\n",
    "        product_links.append(\"https://www2.hm.com\"+product.a['href'])\n",
    "rows=[]\n",
    "for prod in product_links:\n",
    "    values=[]\n",
    "    values.append(prod)\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(prod)\n",
    "    time.sleep(random.uniform(3,7))\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    soup=bs.BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        x=soup.find('dd')\n",
    "        text=x.text\n",
    "        if 'model' in text:\n",
    "            values.append(\"yes\")\n",
    "        else:\n",
    "            if len(soup.find_all('figure',class_=\"pdp-secondary-image pdp-image\"))>=2:\n",
    "                values.append(\"yes\")\n",
    "            else:\n",
    "                values.append(\"no\")\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        r=soup.find('span',class_=\"reviews-number\")\n",
    "        values.append(r.text[9:-1])\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        stars=soup.find_all('span',class_=\"star\")\n",
    "        star_values=[]\n",
    "        for s in range(5):\n",
    "            att=stars[s].attrs\n",
    "            star_values.append(list(att.values())[0])\n",
    "        star_values2=[b for a in star_values for b in a] \n",
    "        if 'full' in star_values2:\n",
    "            ind=star_values2.index('full')\n",
    "            rating=ind\n",
    "        elif 'half' in star_values2:\n",
    "            ind=star_values2.index('half')\n",
    "            rating=ind-0.5\n",
    "        else:\n",
    "            rating=0\n",
    "        values.append(rating)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    try:\n",
    "        desc=soup.find('p',class_=\"pdp-description-text\")\n",
    "        values.append(desc.text)\n",
    "    except:\n",
    "        values.append(None)\n",
    "    rows.append(values)\n",
    "    \n",
    "women_jackets = pd.DataFrame(rows, columns =['product', 'model_present', 'no_of_reviews', 'avg_rating', 'description'])\n",
    "women_jackets.to_csv('women_jackets.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
